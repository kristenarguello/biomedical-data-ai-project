{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpuFXfzmV2sR"
      },
      "source": [
        "This first block of text simply contains all the libraries that need importing as well as initialsing some variables of this example. You may change the batch_size and epochs variables, but should not change num_classes, img_rows and img_cols as these depend on the dataset being used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJTrBwuMKtcr"
      },
      "outputs": [],
      "source": [
        "#Only if needed uncomment the next line\n",
        "#!pip install numpy keras tf-explain matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHhHwGkRWRyC"
      },
      "source": [
        "The next block of text handles all the data loading and reshaping so that it can be used to train and evaluate the CNN models. Two sets of data are loaded, the training data, used to generate the model, and the test data, used to evaluate if this model is good at making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3ESs1_3K2bE"
      },
      "outputs": [],
      "source": [
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdlBqL-FVmVu"
      },
      "source": [
        "This block of code defines the layers of the CNN model, compiles it and shows a textual summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7MNN5mALTCh"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        #layers.BatchNormalization(),\n",
        "        #layers.Dropout(0.25),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        #layers.BatchNormalization(),\n",
        "        #layers.Dropout(0.25),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        #layers.Dense(128,activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgjbtxgEW91a"
      },
      "source": [
        "This is the block of code that trains the model and evaluates its predictive capacity on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP5QbhS4LXZx"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVhXZL29XVNV"
      },
      "source": [
        "This block of code picks an image from the test set (you can change the index to choose a different image), and shows the probabilities that the CNN model estimates for each class (i.e. digit), then shows the actual image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOnYwFGlN4_z"
      },
      "outputs": [],
      "source": [
        "img_index = 42\n",
        "image = x_test[img_index]\n",
        "\n",
        "pred=model.predict(np.expand_dims(image, axis=0))[0]\n",
        "for digit in range(10):\n",
        "        print(\"Probability for digit {}: {}\".format(digit,pred[digit]))\n",
        "print(\"\\nThe winner is {}\".format(np.argmax(pred)))\n",
        "print(\"The correct class is {}\\n\".format(np.argmax(y_test[img_index])))\n",
        "\n",
        "plt.imshow(image.squeeze(),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "STfuydDxv6PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0i-qvzsmrKw"
      },
      "source": [
        "In the next block we are using a specialised library called tf-explain that contains a few advance algorithms to visualise the decision making process of CNNs.\n",
        "\n",
        "This specific example uses one of the available techniques called \"Occlusion sensitivity\". If we block parts of the input image using a square of a certain size (4x4 pixels in the example below), would the output of the network for a given class change? If this is done systematically, the occlusion influence for each pixel in the image can be estimated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLROIQIUOVF6"
      },
      "outputs": [],
      "source": [
        "img_index = 42\n",
        "image = x_test[img_index]\n",
        "data = ([image], None)\n",
        "explainer = OcclusionSensitivity()\n",
        "\n",
        "fig, axs = plt.subplots(1,10,figsize=(25,25))\n",
        "for cl in range(num_classes):\n",
        "  grid = explainer.explain(data, model, cl, 4)\n",
        "  axs[cl].imshow(grid)\n",
        "  axs[cl].axis('off')\n",
        "  axs[cl].set_title(\"Class = {}\".format(cl))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pje81dfLwh1x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}